import logging
import nltk
import os
import fitz  # PyMuPDF
from sklearn.model_selection import train_test_split
import numpy as np
import torch
import json
from PIL import Image
import re
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
import io
import sacrebleu
from dataclasses import dataclass
from transformers import (
    MarianMTModel, 
    MarianTokenizer,
    Trainer, 
    TrainingArguments,
    DataCollatorForSeq2Seq,
    TrainerCallback
)
from typing import List, Dict, Tuple, Any
from torch.utils.data import Dataset
from nltk.tokenize import sent_tokenize
import matplotlib.pyplot as plt
import time

nltk.download('punkt')

# Fix logging format string
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',  # Fixed format string
    encoding='utf-8'
)
logger = logging.getLogger(__name__)

os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # –î–ª—è –ª—É—á—à–µ–π –æ—Ç–ª–∞–¥–∫–∏
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–¥–µ–ª—è–µ–º–æ–π –ø–∞–º—è—Ç–∏
@dataclass
class VisualElement:
    type: str  # 'image', 'table', 'diagram', 'line', 'other'
    bbox: Tuple[float, float, float, float]
    page_num: int
    data: Any  # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —ç–ª–µ–º–µ–Ω—Ç–∞
    properties: Dict  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞
@dataclass
class TranslationConfig:
    model_name: str = "Helsinki-NLP/opus-mt-en-ru"
    max_length: int = 512
    num_beams: int = 4
    train_ratio: float = 0.7
    eval_ratio: float = 0.15
    test_ratio: float = 0.15  # Added missing test_ratio
    learning_rate: float = 2e-5
    weight_decay: float = 0.01
    warmup_steps: int = 500
    num_epochs: int = 3
    preserve_visual_elements: bool = True
    visual_elements_dir: str = "./visual_elements"
    
    def __post_init__(self):
        # Validate ratios add up to 1.0
        total_ratio = self.train_ratio + self.eval_ratio + self.test_ratio
        if not np.isclose(total_ratio, 1.0):
            raise ValueError(f"Sum of ratios must be 1.0, got {total_ratio}")
        
        # Validate ratio ranges
        for ratio_name, ratio_value in [
            ("train_ratio", self.train_ratio),
            ("eval_ratio", self.eval_ratio),
            ("test_ratio", self.test_ratio)
        ]:
            if not (0 <= ratio_value <= 1):
                raise ValueError(f"{ratio_name} must be between 0 and 1")

def clean_text(text: str) -> str:
    """Clean text from PDF artifacts."""
    # Remove hyphenation
    text = re.sub(r'(\w+)-\n(\w+)', r'\1\2', text)
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text)
    # Remove PDF artifacts (you may need to add more patterns)
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\xff]', '', text)
    return text.strip()

class ParallelPDFDataset:
    def __init__(self, source_pdf_dir: str, target_pdf_dir: str, config: TranslationConfig):
        self.source_pdf_dir = source_pdf_dir
        self.target_pdf_dir = target_pdf_dir
        self.pairs = []
        self.aligned_texts = []
        self.config = config
        
    def extract_text_from_pdf(self, pdf_path: str) -> List[Dict]:
        text_blocks = []
        try:
            doc = fitz.open(pdf_path)
            for page_num in range(len(doc)):
                page = doc[page_num]
                blocks = page.get_text("dict")["blocks"]
                
                for block in blocks:
                    if "lines" in block:
                        text = ""
                        for line in block["lines"]:
                            for span in line["spans"]:
                                text += span['text'] + " "
                        
                        # Clean and split into sentences
                        clean = clean_text(text)
                        if clean:
                            sentences = sent_tokenize(clean)
                            for sent in sentences:
                                if sent.strip():
                                    text_blocks.append({
                                        'text': sent.strip(),
                                        'bbox': block['bbox'],
                                        'page_num': page_num
                                    })
            if not text_blocks:
                logger.warning(f"No text extracted from {pdf_path}")
            return text_blocks
        except Exception as e:
            logger.error(f"Error extracting text from PDF {pdf_path}: {str(e)}")
            return []

    def align_texts(self, source_blocks: List[Dict], target_blocks: List[Dict]) -> List[Tuple[str, str]]:
        """Improved text alignment using multiple criteria."""
        aligned_pairs = []
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
        def normalize_text(text: str) -> str:
            # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ —Ü–∏—Ñ—Ä—ã
            text = re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø\s]', '', text.lower())
            return text.strip()
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∞–º–∏/–∫–æ–¥–∞–º–∏
        def is_number_or_code(text: str) -> bool:
            return bool(re.match(r'^[0-9/-]*$', text.strip()))
        
        # Group blocks by page
        source_by_page = {}
        target_by_page = {}
        
        for block in source_blocks:
            page = block['page_num']
            if page not in source_by_page:
                source_by_page[page] = []
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∞ –∏–ª–∏ –∫–æ–¥—ã
            if not is_number_or_code(block['text']):
                source_by_page[page].append(block)
                
        for block in target_blocks:
            page = block['page_num']
            if page not in target_by_page:
                target_by_page[page] = []
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∞ –∏–ª–∏ –∫–æ–¥—ã
            if not is_number_or_code(block['text']):
                target_by_page[page].append(block)
        
        # Align sentences page by page
        for page in source_by_page.keys():
            if page in target_by_page:
                source_page = sorted(source_by_page[page], key=lambda x: (x['bbox'][1], x['bbox'][0]))
                target_page = sorted(target_by_page[page], key=lambda x: (x['bbox'][1], x['bbox'][0]))
                
                s_idx = t_idx = 0
                while s_idx < len(source_page) and t_idx < len(target_page):
                    source_block = source_page[s_idx]
                    target_block = target_page[t_idx]
                    
                    source_text = source_block['text'].strip()
                    target_text = target_block['text'].strip()
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –±–ª–æ–∫–∏ –∏–ª–∏ –±–ª–æ–∫–∏ —Ç–æ–ª—å–∫–æ —Å —á–∏—Å–ª–∞–º–∏
                    if not source_text or not target_text or \
                    is_number_or_code(source_text) or is_number_or_code(target_text):
                        s_idx += 1
                        t_idx += 1
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–∏–∑–æ—Å—Ç—å –±–ª–æ–∫–æ–≤ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏
                    vertical_distance = abs(source_block['bbox'][1] - target_block['bbox'][1])
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
                    len_ratio = len(source_text) / len(target_text) if len(target_text) > 0 else float('inf')
                    
                    # –ï—Å–ª–∏ –±–ª–æ–∫–∏ –±–ª–∏–∑–∫–∏ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ –∏ –∏–º–µ—é—Ç —Å—Ö–æ–∂—É—é –¥–ª–∏–Ω—É
                    if vertical_distance < 50 and 0.5 < len_ratio < 2.0:
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–±–∞ —Ç–µ–∫—Å—Ç–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç –±—É–∫–≤—ã
                        if re.search('[a-zA-Z–∞-—è–ê-–Ø]', source_text) and re.search('[a-zA-Z–∞-—è–ê-–Ø]', target_text):
                            aligned_pairs.append((source_text, target_text))
                        s_idx += 1
                        t_idx += 1
                    elif source_block['bbox'][1] < target_block['bbox'][1]:
                        s_idx += 1
                    else:
                        t_idx += 1
         # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        with open('parallel_texts_debug.json', 'w', encoding='utf-8') as f:
            debug_data = {
                'source_blocks': [{'text': b['text'], 'bbox': b['bbox'], 'page': b['page_num']} 
                                for p in self.pairs for b in self.extract_text_from_pdf(p[0])],
                'target_blocks': [{'text': b['text'], 'bbox': b['bbox'], 'page': b['page_num']} 
                                for p in self.pairs for b in self.extract_text_from_pdf(p[1])],
                'aligned_pairs': self.aligned_texts
            }
            json.dump(debug_data, f, ensure_ascii=False, indent=2)
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        filtered_pairs = []
        for source, target in aligned_pairs:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –∏ –Ω–∞–ª–∏—á–∏–µ –±—É–∫–≤
            if (len(source) > 5 and len(target) > 5 and 
                re.search('[a-zA-Z–∞-—è–ê-–Ø]', source) and 
                re.search('[a-zA-Z–∞-—è–ê-–Ø]', target)):
                filtered_pairs.append((source, target))
        
        logger.info(f"Found {len(filtered_pairs)} valid text pairs after filtering")
        return filtered_pairs
   
    def load_data(self):
        source_texts = []
        target_texts = []
        
        # Load and validate source PDFs
        for pdf in os.listdir(self.source_pdf_dir):
            if pdf.endswith('.pdf'):
                source_blocks = self.extract_text_from_pdf(os.path.join(self.source_pdf_dir, pdf))
                if source_blocks:
                    source_texts.extend(source_blocks)
                    
        # Load and validate target PDFs  
        for pdf in os.listdir(self.target_pdf_dir):
            if pdf.endswith('.pdf'):
                target_blocks = self.extract_text_from_pdf(os.path.join(self.target_pdf_dir, pdf))
                if target_blocks:
                    target_texts.extend(target_blocks)

        if not source_texts or not target_texts:
            logger.error("No valid text found in PDFs")
            return [], [], []

        # Align texts and split into train/eval/test
        aligned_texts = self.align_texts(source_texts, target_texts)
        return self.split_data(aligned_texts)

    def split_data(self, aligned_texts):
        if not aligned_texts:
            logger.warning("No aligned texts found!")
            return [], [], []
        
        if len(aligned_texts) < 3:
            logger.warning("Too few samples to split into train/eval/test sets!")
            return aligned_texts, [], []
        
        # Split data
        train_data, temp_data = train_test_split(
            aligned_texts, 
            train_size=self.config.train_ratio,
            random_state=42
        )
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ eval/test –∏–∑ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö
        remaining_ratio = 1.0 - self.config.train_ratio
        if remaining_ratio > 0:
            eval_ratio_adjusted = self.config.eval_ratio / remaining_ratio
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ –Ω–∞ eval –∏ test
            eval_data, test_data = train_test_split(
                temp_data,
                train_size=eval_ratio_adjusted,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º train_size –≤–º–µ—Å—Ç–æ test_size
                random_state=42
            )
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ –Ω–∞–±–æ—Ä—ã
            eval_data = []
            test_data = []
        
        logger.info(f"Dataset split: train={len(train_data)}, eval={len(eval_data)}, test={len(test_data)}")
        return train_data, eval_data, test_data

class CustomDataset(Dataset):
    def __init__(self, data, tokenizer, max_length):
        self.data = data
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        source_text, target_text = self.data[idx]
        
        # Tokenize source
        source_encoded = self.tokenizer(
            source_text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        # Tokenize target
        target_encoded = self.tokenizer(
            text=target_text,  # Changed from text_target
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )

        # Return tensors without requiring gradients
        return {
            'input_ids': source_encoded['input_ids'].squeeze(0),
            'attention_mask': source_encoded['attention_mask'].squeeze(0),
            'labels': target_encoded['input_ids'].squeeze(0)
        }

class TranslationMetrics:
    def __init__(self, tokenizer):
        self.tokenizer = tokenizer
        
    def compute_metrics(self, pred):
        try:
            # Handle nested predictions
            predictions = pred.predictions
            if isinstance(predictions, tuple):
                predictions = predictions[0]
            
            labels = pred.label_ids
            
            # Decode predictions and labels
            predicted_texts = self.tokenizer.batch_decode(
                predictions, 
                skip_special_tokens=True
            )
            
            label_texts = self.tokenizer.batch_decode(
                labels,
                skip_special_tokens=True
            )
            
            # Calculate BLEU score
            bleu = sacrebleu.corpus_bleu(
                predicted_texts, 
                [[text] for text in label_texts]
            )
            
            return {
                "bleu": bleu.score,
                "num_samples": len(predicted_texts)
            }
            
        except Exception as e:
            logger.error(f"Metrics computation error: {e}")
            return {"bleu": 0.0, "error": str(e)}

class PDFVisualExtractor:
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.doc = fitz.open(pdf_path)
        self.visual_elements = []

    def extract_images(self, page_num: int) -> List[VisualElement]:
        """Extract images with color profile handling"""
        page = self.doc[page_num]
        images = []
        
        for img in page.get_images(full=True):
            try:
                xref = img[0]
                base_image = self.doc.extract_image(xref)
                
                # Handle image data
                image_data = base_image["image"]
                
                # Convert image to RGB if needed
                try:
                    pil_image = Image.open(io.BytesIO(image_data))
                    if pil_image.mode in ['CMYK', 'P']:
                        pil_image = pil_image.convert('RGB')
                    
                    # Convert back to bytes
                    img_byte_arr = io.BytesIO()
                    pil_image.save(img_byte_arr, format='PNG')
                    image_data = img_byte_arr.getvalue()
                    
                except Exception as e:
                    logger.warning(f"Image conversion failed: {e}, using original")
                
                # Get image position
                image_rect = page.get_image_bbox(img)
                
                images.append(VisualElement(
                    type='image',
                    bbox=image_rect,
                    data=image_data,
                    page_num=page_num,
                    properties={
                        'format': 'png',  # Always use PNG for consistency
                        'colorspace': 'rgb'
                    }
                ))
                
            except Exception as e:
                logger.error(f"Error extracting image: {e}")
                continue
                
        return images

    def extract_tables(self, page_num: int) -> List[VisualElement]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        page = self.doc[page_num]
        tables = []
        
        # –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü –ø–æ –ª–∏–Ω–∏—è–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        blocks = page.get_text("dict")["blocks"]
        for block in blocks:
            if block.get("type") == 1:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –±–ª–æ–∫ —Ç–∞–±–ª–∏—Ü–µ–π
                tables.append(VisualElement(
                    type='table',
                    bbox=tuple(block["bbox"]),
                    page_num=page_num,
                    data=block,
                    properties={'cells': block.get("lines", [])}
                ))
        return tables

    def extract_lines(self, page_num: int) -> List[VisualElement]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ª–∏–Ω–∏–∏ —Ä–∞–∑–º–µ—Ç–∫–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        page = self.doc[page_num]
        paths = page.get_drawings()
        lines = []
        
        for path in paths:
            if path["type"] == "l":  # –ª–∏–Ω–∏—è
                lines.append(VisualElement(
                    type='line',
                    bbox=tuple(path["rect"]),
                    page_num=page_num,
                    data=path,
                    properties={
                        'color': path.get("color", (0, 0, 0)),
                        'width': path.get("width", 1),
                        'style': path.get("style", "solid")
                    }
                ))
        return lines

    def extract_all_elements(self):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ PDF."""
        for page_num in range(len(self.doc)):
            self.visual_elements.extend(self.extract_images(page_num))
            self.visual_elements.extend(self.extract_tables(page_num))
            self.visual_elements.extend(self.extract_lines(page_num))
        
        return self.visual_elements

    def save_elements_data(self, output_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –≤ JSON."""
        try:
            base_dir = os.path.dirname(output_path)
            os.makedirs(base_dir, exist_ok=True)
            
            images_dir = f"{output_path}_images"
            os.makedirs(images_dir, exist_ok=True)
            
            elements_data = []
            for elem in self.visual_elements:
                # Convert Rect and other non-serializable objects to basic types
                elem_dict = {
                    'type': elem.type,
                    'bbox': tuple(elem.bbox) if hasattr(elem.bbox, '__iter__') else elem.bbox,
                    'page_num': elem.page_num,
                    'properties': {
                        k: tuple(v) if isinstance(v, (fitz.Rect, tuple, list)) else v
                        for k, v in elem.properties.items()
                    }
                }
                
                if elem.type == 'image':
                    img_filename = f"{len(elements_data)}.{elem_dict['properties'].get('format', 'png')}"
                    img_path = os.path.join(images_dir, img_filename)
                    os.makedirs(os.path.dirname(img_path), exist_ok=True)
                    
                    with open(img_path, 'wb') as f:
                        f.write(elem.data)
                    elem_dict['data'] = img_path
                else:
                    # Convert non-image data to serializable format
                    elem_dict['data'] = str(elem.data)
                
                elements_data.append(elem_dict)
            
            # Save JSON metadata
            with open(f"{output_path}.json", 'w', encoding='utf-8') as f:
                json.dump(elements_data, f, ensure_ascii=False, indent=4, default=str)
                
            logger.info(f"Saved visual elements to {output_path}")
            
        except Exception as e:
            logger.error(f"Error saving visual elements: {str(e)}")
            raise

class PDFReconstructor:
    def __init__(self, elements_data: List[VisualElement], translated_text: Dict):
        self.elements = elements_data
        self.translated_text = translated_text

    def create_pdf(self, output_path: str):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π PDF —Å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏."""
        c = canvas.Canvas(output_path, pagesize=letter)
        
        current_page = 0
        page_elements = [e for e in self.elements if e.page_num == current_page]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for elem in page_elements:
            if elem.type == 'image':
                self._add_image(c, elem)
            elif elem.type == 'line':
                self._add_line(c, elem)
            elif elem.type == 'table':
                self._add_table(c, elem)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        if current_page in self.translated_text:
            for text_block in self.translated_text[current_page]:
                c.drawString(text_block['x'], text_block['y'], text_block['text'])
        
        c.save()

    def _add_image(self, canvas, element):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PDF."""
        if isinstance(element.data, bytes):
            img = Image.open(io.BytesIO(element.data))
            canvas.drawImage(img, *element.bbox)

    def _add_line(self, canvas, element):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏–Ω–∏—é –≤ PDF."""
        canvas.setStrokeColor(element.properties['color'])
        canvas.setLineWidth(element.properties['width'])
        canvas.line(*element.bbox)

    def _add_table(self, canvas, element):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–∞–±–ª–∏—Ü—É –≤ PDF."""
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        pass

from sacrebleu.metrics import BLEU
import numpy as np

class PDFTranslationModel:
    def __init__(self, config: TranslationConfig):
        self.config = config
        
        try:
            # Load model and tokenizer
            self.model = MarianMTModel.from_pretrained(config.model_name)
            self.tokenizer = MarianTokenizer.from_pretrained(config.model_name)
            
            # Enable all parameters for training
            for param in self.model.parameters():
                param.requires_grad = True
            
            # Move model to GPU if available
            if torch.cuda.is_available():
                self.model = self.model.cuda()
                logger.info("Model moved to GPU")
            
            # Log trainable parameters
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            logger.info(f"Number of trainable parameters: {trainable_params}")
            
            # Initialize metrics calculator
            self.bleu = BLEU()
            
        except Exception as e:
            logger.error(f"Error initializing model: {str(e)}")
            raise

    def process_pdf(self, pdf_path: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ PDF —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤."""
        if self.config.preserve_visual_elements:
            self.visual_extractor = PDFVisualExtractor(pdf_path)
            elements = self.visual_extractor.extract_all_elements()
            self.visual_extractor.save_elements_data(
                os.path.join(self.config.visual_elements_dir, 
                            os.path.basename(pdf_path))
            )
    
    def compute_metrics(self, eval_pred):
        """Compute evaluation metrics."""
        try:
            predictions, labels = eval_pred

            if isinstance(predictions, tuple):
                predictions = predictions[0]

            decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)
            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)

            decoded_preds = [pred.strip() for pred in decoded_preds]
            decoded_labels = [[label.strip()] for label in decoded_labels]  # <-- –∑–¥–µ—Å—å

            # üõ† –í–æ–∑–º–æ–∂–Ω–æ, labels –≤ —Ñ–æ—Ä–º–∞—Ç–µ list of lists, –ø–æ–ø—Ä–æ–±—É–µ–º:
            if isinstance(decoded_labels[0], list):
                decoded_labels = [l[0] for l in decoded_labels]  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ list of strings

            bleu_score = self.bleu.corpus_score(decoded_preds, [decoded_labels])  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç

            return {
                "bleu": bleu_score.score,
                "num_samples": len(decoded_preds)
            }

        except Exception as e:
            logger.error(f"Error computing metrics: {str(e)}")
            return {"bleu": 0.0, "error": str(e)}

    def train(self, train_dataset, eval_dataset, test_dataset, save_dir="./final_model"):
        try:
            callback = ModelCallback(save_dir)
            
            training_args = TrainingArguments(
                output_dir=save_dir,
                num_train_epochs=self.config.num_epochs,
                per_device_train_batch_size=2,
                gradient_accumulation_steps=2,
                eval_accumulation_steps=2,  # –£–º–µ–Ω—å—à–∞–µ–º –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ eval
                learning_rate=self.config.learning_rate,
                fp16=True,  # –í–∫–ª—é—á–∞–µ–º mixed precision, –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
                weight_decay=self.config.weight_decay,
                warmup_steps=self.config.warmup_steps,
                logging_dir='./logs',
                logging_steps=2,
                eval_steps=2,
                eval_strategy="steps",  # Updated from evaluation_strategy
                save_strategy="steps",
                save_steps=100,
                logging_first_step=True,
                load_best_model_at_end=True,
                metric_for_best_model="bleu"
            )

            trainer = Trainer(
                model=self.model,
                args=training_args,
                train_dataset=train_dataset,
                eval_dataset=eval_dataset,
                callbacks=[callback],
                compute_metrics=self.compute_metrics,
                processing_class=self.tokenizer  # Updated from tokenizer
            )
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º eval_dataset –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º Trainer
            if len(eval_dataset) == 0:
                logger.warning("‚ö†Ô∏è eval_dataset –ø—É—Å—Ç! –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞!")
            # Train and save
            trainer.train()
            trainer.save_model(save_dir)
            self.tokenizer.save_pretrained(save_dir)
            
            # Save training history
            np.save(f"{save_dir}/training_history.npy", callback.history)
            
            # Final evaluation
            test_results = trainer.evaluate(test_dataset)
            logger.info(f"Test results: {test_results}")

        except Exception as e:
            logger.error(f"Training error: {str(e)}")
            raise

class ModelCallback(TrainerCallback):
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.history = {
            'train_loss': [],
            'eval_loss': [],
            'bleu_score': [],
            'learning_rate': [],
            'epoch': []
        }
        self.start_time = time.time()
        os.makedirs(output_dir, exist_ok=True)
    
    def on_log(self, args, state, control, logs=None, **kwargs):
        """Called when logging occurs"""
        if logs:
            logger.info(f"Trainer logs: {logs}")  # –ü–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ Trainer —Ä–µ–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞–µ—Ç

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            if 'loss' in logs:
                self.history['train_loss'].append(logs['loss'])
                logger.info(f"Train loss: {logs['loss']:.4f}")
                    
            if 'eval_loss' in logs:
                self.history['eval_loss'].append(logs['eval_loss'])
                logger.info(f"Eval loss: {logs['eval_loss']:.4f}")
                    
            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–ª—é—á BLEU
            if 'eval_bleu' in logs:
                self.history['bleu_score'].append(logs['eval_bleu'])
                logger.info(f"BLEU score: {logs['eval_bleu']:.4f}")
                    
            if 'learning_rate' in logs:
                self.history['learning_rate'].append(logs['learning_rate'])
                logger.info(f"Learning Rate: {logs['learning_rate']:.6f}")

            if 'epoch' in logs:
                self.history['epoch'].append(logs['epoch'])
                logger.info(f"Epoch: {logs['epoch']:.2f}")

            # –õ–æ–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
            logger.info(f"Current history state: {self.history}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—å –æ–¥–Ω–∞ –∑–∞–ø–∏—Å–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
            if any(len(v) > 0 for v in self.history.values()):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
                np.save(f"{self.output_dir}/training_history.npy", self.history)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫
                self.plot_progress()


    def plot_progress(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö –ª–∏–Ω–∏–π"""
        if not any(self.history.values()):
            logger.warning("–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –ø—É—Å—Ç–∞, –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–µ –±—É–¥—É—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã")
            return  # –í—ã—Ö–æ–¥–∏–º, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç

        plt.figure(figsize=(12, 8))

        # Training & Evaluation Loss
        plt.subplot(2, 2, 1)
        if self.history['train_loss']:
            plt.plot(self.history['train_loss'], label='Train Loss', color='blue')
        
        if self.history['eval_loss']:
            plt.plot(self.history['eval_loss'], label='Eval Loss', color='red')

        if self.history['bleu_score']:
            plt.plot(self.history['bleu_score'], label='BLEU Score', color='green')

        plt.title('Training and Evaluation Loss')
        plt.xlabel('Steps')
        plt.ylabel('Loss')
        plt.legend()

        # BLEU Score
        plt.subplot(2, 2, 2)
        if self.history['bleu_score']:
            plt.plot(self.history['bleu_score'], label='BLEU Score', color='green')
            plt.title('BLEU Score Over Time')
            plt.xlabel('Eval Steps')
            plt.ylabel('BLEU')
            plt.legend()

        # Learning Rate
        plt.subplot(2, 2, 3)
        if self.history['learning_rate']:
            plt.plot(self.history['learning_rate'], label='Learning Rate', color='orange')
            plt.title('Learning Rate Progression')
            plt.xlabel('Steps')
            plt.ylabel('LR')
            plt.legend()

        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/training_progress.png")
        plt.close()


def main():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        logger.info(f"Using GPU: {torch.cuda.get_device_name(0)}")
    
    try:
        config = TranslationConfig()
        
        # Create visual elements directory
        os.makedirs(config.visual_elements_dir, exist_ok=True)
        
        # Initialize dataset and process PDFs
        dataset = ParallelPDFDataset("source_pdfs", "target_pdfs", config)
        
        # Extract visual elements before loading data
        logger.info("Extracting visual elements from PDFs...")
        for pdf_file in os.listdir("source_pdfs"):
            if pdf_file.endswith('.pdf'):
                pdf_path = os.path.join("source_pdfs", pdf_file)
                extractor = PDFVisualExtractor(pdf_path)
                elements = extractor.extract_all_elements()
                
                # Save visual elements
                output_path = os.path.join(config.visual_elements_dir, f"{os.path.splitext(pdf_file)[0]}_elements")
                extractor.save_elements_data(output_path)
                logger.info(f"Saved visual elements for {pdf_file}")
        
        # Load data and continue with training
        train_data, eval_data, test_data = dataset.load_data()
        
        # Save parallel texts
        with open("parallel_texts.json", "w", encoding="utf-8") as f:
            json.dump({
                "train": train_data,
                "eval": eval_data,
                "test": test_data
            }, f, ensure_ascii=False, indent=4)
        
        # Initialize and train model
        translation_model = PDFTranslationModel(config=config)
        train_dataset = CustomDataset(train_data, translation_model.tokenizer, config.max_length)
        eval_dataset = CustomDataset(eval_data, translation_model.tokenizer, config.max_length)
        test_dataset = CustomDataset(test_data, translation_model.tokenizer, config.max_length)
        
        translation_model.train(train_dataset, eval_dataset, test_dataset)
        logger.info("Training completed successfully!")
        
    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
        raise
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

if __name__ == "__main__":
    main()